# -*- coding: utf-8 -*-
"""atari_games.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/atari_games.ipynb

# Stable Baselines3 - Train on Atari Games

Github Repo: [https://github.com/DLR-RM/stable-baselines3](https://github.com/DLR-RM/stable-baselines3)


[RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo) is a training framework for Reinforcement Learning (RL), using Stable Baselines3.

It provides scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos.

Documentation is available online: [https://stable-baselines3.readthedocs.io/](https://stable-baselines3.readthedocs.io/)

## Install Dependencies and Stable Baselines Using Pip


```
pip install stable-baselines3[extra]
```
"""

"""## Import policy, RL agent, ..."""

from stable_baselines3 import A2C
from sb3_contrib import QRDQN
from stable_baselines3.common.env_util import make_atari_env
from stable_baselines3.common.vec_env import VecFrameStack
import ale_py


# There already exists an environment generator that will make and wrap atari environments correctly.
env = make_atari_env("PongNoFrameskip-v4", n_envs=4, seed=0)
# Stack 4 frames
env = VecFrameStack(env, n_stack=4)

policy_kwargs = dict(n_quantiles=200)
model = QRDQN(
    "CnnPolicy",
    env,
    policy_kwargs=policy_kwargs,
    verbose=1,
    tensorboard_log="./qrdqn_pong_tensorboard/",
)
# model = A2C("CnnPolicy", env, verbose=1, tensorboard_log="./a2c_pong_tensorboard/")
model.learn(total_timesteps=1_000_000, progress_bar=True, log_interval=10)
